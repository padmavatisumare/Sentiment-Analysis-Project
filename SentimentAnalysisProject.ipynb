{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpK8hbExE5xRHvurMb1reC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/padmavatisumare/Sentiment-Analysis-Project/blob/main/SentimentAnalysisProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Data\n",
        "import pandas as pd\n",
        "\n",
        "file_path = r\"/content/tweets.csv.csv\"\n",
        "df = pd.read_csv(file_path, encoding='latin-1', header=None)\n",
        "\n",
        "# Add column names\n",
        "df.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
        "\n",
        "print(\"Data loaded successfully âœ…\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UohNiHmxDva8",
        "outputId": "7cae133d-2deb-4b45-b22d-cd4f29693468"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully âœ…\n",
            "   target          id                          date      flag  \\\n",
            "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
            "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "\n",
            "              user                                               text  \n",
            "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
            "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
            "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
            "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
            "4           Karoli  @nationwideclass no, it's not behaving at all....  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocess Data\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Keep only positive (4) and negative (0) tweets\n",
        "df = df[df['target'].isin([0, 4])]\n",
        "df['target'] = df['target'].replace({0: 0, 4: 1})  # 0: Negative, 1: Positive\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+\", '', text)  # Remove links, mentions, hashtags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuations/numbers\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(\"Data preprocessing done âœ…\")\n",
        "print(df[['text', 'clean_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybrxcbpEKHOY",
        "outputId": "6f57ea24-79f8-43ef-9ba9-7245adaff766"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing done âœ…\n",
            "                                                text  \\\n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
            "1  is upset that he can't update his Facebook by ...   \n",
            "2  @Kenichan I dived many times for the ball. Man...   \n",
            "3    my whole body feels itchy and like its on fire    \n",
            "4  @nationwideclass no, it's not behaving at all....   \n",
            "\n",
            "                                          clean_text  \n",
            "0      thats bummer shoulda got david carr third day  \n",
            "1  upset cant update facebook texting might cry r...  \n",
            "2  dived many times ball managed save rest go bounds  \n",
            "3                   whole body feels itchy like fire  \n",
            "4                           behaving im mad cant see  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Vectorize Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['target']\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "print(\"Text vectorization completed âœ…\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41-hw1zxLUaq",
        "outputId": "307b6424-55b3-4188-885f-889801543ac1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text vectorization completed âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training done âœ…\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7jUKuopLowS",
        "outputId": "d694ad96-294c-4f22-b32c-df85873d29f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training done âœ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluate Model\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Model Evaluation Results âœ…\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L2zAYyFLz29",
        "outputId": "d5b95c36-e57f-482b-f506-494d8686278c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation Results âœ…\n",
            "Accuracy: 0.77343125\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.75      0.77    159494\n",
            "           1       0.76      0.80      0.78    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Predict on New Data\n",
        "def predict_sentiment(tweet):\n",
        "    tweet = clean_text(tweet)\n",
        "    tweet_vec = vectorizer.transform([tweet])\n",
        "    prediction = model.predict(tweet_vec)\n",
        "    return \"Positive ðŸ˜€\" if prediction[0] == 1 else \"Negative ðŸ˜ž\"\n",
        "\n",
        "# Example predictions\n",
        "print(predict_sentiment(\"I love this product! It's amazing.\"))\n",
        "print(predict_sentiment(\"This is the worst thing ever.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG94CuoSMGqm",
        "outputId": "1e9d03e1-4031-41dd-9bec-529352fe896d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive ðŸ˜€\n",
            "Negative ðŸ˜ž\n"
          ]
        }
      ]
    }
  ]
}